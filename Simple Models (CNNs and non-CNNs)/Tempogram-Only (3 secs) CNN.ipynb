{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Tempogram (3 secs)\n",
    "\n",
    "## 1 - All 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Normalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Augmentation function\n",
    "def augment_image(image):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    return image\n",
    "\n",
    "# Define the genres and file paths\n",
    "GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "FILE_PATH = os.path.join('Data', 'tempograms (3 secs)')\n",
    "\n",
    "GENRE_TO_INDEX = {genre: index for index, genre in enumerate(GENRES)}\n",
    "\n",
    "# Organize data by song ID\n",
    "song_to_clips = {}\n",
    "\n",
    "for genre in GENRES:\n",
    "    genre_dir = os.path.join(FILE_PATH, genre)\n",
    "    print(f\"Processing genre: {genre}\")\n",
    "    for file in os.listdir(genre_dir):\n",
    "        if not file.endswith(\".png\"):\n",
    "            continue\n",
    "        \n",
    "        song_id = file.split(\"_clip_\")[0]  # Extract song ID (e.g., \"blues.00042\")\n",
    "        \n",
    "        if song_id not in song_to_clips:\n",
    "            song_to_clips[song_id] = []\n",
    "\n",
    "        image = tf.io.read_file(os.path.join(genre_dir, file))\n",
    "        image = tf.image.decode_png(image, channels=1)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        image = tf.image.resize(image, [256, 256])  # Resize to 256x256\n",
    "        image = augment_image(image)  # Apply augmentation\n",
    "        image = image.numpy()  # Convert to numpy array\n",
    "        \n",
    "        song_to_clips[song_id].append((image, GENRE_TO_INDEX[genre]))\n",
    "\n",
    "# Convert dictionary to list format\n",
    "song_ids = list(song_to_clips.keys())\n",
    "train_ids, test_ids = train_test_split(song_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, y_train, X_test, y_test = [], [], [], []\n",
    "\n",
    "# Assign clips based on the train-test split\n",
    "for song_id in song_ids:\n",
    "    clips = song_to_clips[song_id]\n",
    "    if song_id in train_ids:\n",
    "        for image, label in clips:\n",
    "            X_train.append(image)\n",
    "            y_train.append(label)\n",
    "    else:\n",
    "        for image, label in clips:\n",
    "            X_test.append(image)\n",
    "            y_test.append(label)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(f\"Train set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)),\n",
    "    Normalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Normalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    Normalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    Normalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(128, activation='relu'), \n",
    "    Dense(len(GENRES), activation='softmax')  # Output size matches number of genres\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Learning rate adjustment\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=32, callbacks=[reduce_lr])\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {evaluation[1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the confusion matrix after the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from sklearn.metrics import confusion\n",
    "import numpy as NP\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnn_preds = np.argmax(model.predict(X_test), axis=1)\n",
    "cnn_cm = confusion_matrix(y_test, cnn_preds)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cnn_cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=GENRES, yticklabels=GENRES)\n",
    "plt.title(\"CNN Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Limited Genres Easy (metal and classical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Normalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Augmentation function\n",
    "def augment_image(image):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    return image\n",
    "\n",
    "# Define the genres and file paths\n",
    "GENRES = ['classical', 'metal']\n",
    "FILE_PATH = os.path.join('Data', 'tempograms (3 secs)')\n",
    "\n",
    "GENRE_TO_INDEX = {genre: index for index, genre in enumerate(GENRES)}\n",
    "\n",
    "# Organize data by song ID\n",
    "song_to_clips = {}\n",
    "\n",
    "for genre in GENRES:\n",
    "    genre_dir = os.path.join(FILE_PATH, genre)\n",
    "    print(f\"Processing genre: {genre}\")\n",
    "    for file in os.listdir(genre_dir):\n",
    "        if not file.endswith(\".png\"):\n",
    "            continue\n",
    "        \n",
    "        song_id = file.split(\"_clip_\")[0]  # Extract song ID (e.g., \"blues.00042\")\n",
    "        \n",
    "        if song_id not in song_to_clips:\n",
    "            song_to_clips[song_id] = []\n",
    "\n",
    "        image = tf.io.read_file(os.path.join(genre_dir, file))\n",
    "        image = tf.image.decode_png(image, channels=1)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        image = tf.image.resize(image, [256, 256])  # Resize to 256x256\n",
    "        image = augment_image(image)  # Apply augmentation\n",
    "        image = image.numpy()  # Convert to numpy array\n",
    "        \n",
    "        song_to_clips[song_id].append((image, GENRE_TO_INDEX[genre]))\n",
    "\n",
    "# Convert dictionary to list format\n",
    "song_ids = list(song_to_clips.keys())\n",
    "train_ids, test_ids = train_test_split(song_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, y_train, X_test, y_test = [], [], [], []\n",
    "\n",
    "# Assign clips based on the train-test split\n",
    "for song_id in song_ids:\n",
    "    clips = song_to_clips[song_id]\n",
    "    if song_id in train_ids:\n",
    "        for image, label in clips:\n",
    "            X_train.append(image)\n",
    "            y_train.append(label)\n",
    "    else:\n",
    "        for image, label in clips:\n",
    "            X_test.append(image)\n",
    "            y_test.append(label)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(f\"Train set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)),\n",
    "    Normalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Normalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    Normalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    Normalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(128, activation='relu'), \n",
    "    Dense(len(GENRES), activation='softmax')  # Output size matches number of genres\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Learning rate adjustment\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=32, callbacks=[reduce_lr])\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {evaluation[1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Easy (classical and metal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from sklearn.metrics import confusion\n",
    "import numpy as NP\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnn_preds = np.argmax(model.predict(X_test), axis=1)\n",
    "cnn_cm = confusion_matrix(y_test, cnn_preds)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cnn_cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=GENRES, yticklabels=GENRES)\n",
    "plt.title(\"CNN Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Limited genres Hard (disco and pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Normalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Augmentation function\n",
    "def augment_image(image):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    return image\n",
    "\n",
    "# Define the genres and file paths\n",
    "GENRES = ['disco', 'pop']\n",
    "FILE_PATH = os.path.join('Data', 'tempograms (3 secs)')\n",
    "\n",
    "GENRE_TO_INDEX = {genre: index for index, genre in enumerate(GENRES)}\n",
    "\n",
    "# Organize data by song ID\n",
    "song_to_clips = {}\n",
    "\n",
    "for genre in GENRES:\n",
    "    genre_dir = os.path.join(FILE_PATH, genre)\n",
    "    print(f\"Processing genre: {genre}\")\n",
    "    for file in os.listdir(genre_dir):\n",
    "        if not file.endswith(\".png\"):\n",
    "            continue\n",
    "        \n",
    "        song_id = file.split(\"_clip_\")[0]  # Extract song ID (e.g., \"blues.00042\")\n",
    "        \n",
    "        if song_id not in song_to_clips:\n",
    "            song_to_clips[song_id] = []\n",
    "\n",
    "        image = tf.io.read_file(os.path.join(genre_dir, file))\n",
    "        image = tf.image.decode_png(image, channels=1)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        image = tf.image.resize(image, [256, 256])  # Resize to 256x256\n",
    "        image = augment_image(image)  # Apply augmentation\n",
    "        image = image.numpy()  # Convert to numpy array\n",
    "        \n",
    "        song_to_clips[song_id].append((image, GENRE_TO_INDEX[genre]))\n",
    "\n",
    "# Convert dictionary to list format\n",
    "song_ids = list(song_to_clips.keys())\n",
    "train_ids, test_ids = train_test_split(song_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, y_train, X_test, y_test = [], [], [], []\n",
    "\n",
    "# Assign clips based on the train-test split\n",
    "for song_id in song_ids:\n",
    "    clips = song_to_clips[song_id]\n",
    "    if song_id in train_ids:\n",
    "        for image, label in clips:\n",
    "            X_train.append(image)\n",
    "            y_train.append(label)\n",
    "    else:\n",
    "        for image, label in clips:\n",
    "            X_test.append(image)\n",
    "            y_test.append(label)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(f\"Train set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)),\n",
    "    Normalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Normalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    Normalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    Normalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(128, activation='relu'), \n",
    "    Dense(len(GENRES), activation='softmax')  # Output size matches number of genres\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Learning rate adjustment\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=32, callbacks=[reduce_lr])\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {evaluation[1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Hard (disco and pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from sklearn.metrics import confusion\n",
    "import numpy as NP\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnn_preds = np.argmax(model.predict(X_test), axis=1)\n",
    "cnn_cm = confusion_matrix(y_test, cnn_preds)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cnn_cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=GENRES, yticklabels=GENRES)\n",
    "plt.title(\"CNN Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Limited Genres Medium (5 random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Normalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Augmentation function\n",
    "def augment_image(image):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    return image\n",
    "\n",
    "GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "GENRES = random.sample(GENRES, 5)\n",
    "print(GENRES)\n",
    "FILE_PATH = os.path.join('Data', 'tempograms (3 secs)')\n",
    "\n",
    "GENRE_TO_INDEX = {genre: index for index, genre in enumerate(GENRES)}\n",
    "\n",
    "# Organize data by song ID\n",
    "song_to_clips = {}\n",
    "\n",
    "for genre in GENRES:\n",
    "    genre_dir = os.path.join(FILE_PATH, genre)\n",
    "    print(f\"Processing genre: {genre}\")\n",
    "    for file in os.listdir(genre_dir):\n",
    "        if not file.endswith(\".png\"):\n",
    "            continue\n",
    "        \n",
    "        song_id = file.split(\"_clip_\")[0]  # Extract song ID (e.g., \"blues.00042\")\n",
    "        \n",
    "        if song_id not in song_to_clips:\n",
    "            song_to_clips[song_id] = []\n",
    "\n",
    "        image = tf.io.read_file(os.path.join(genre_dir, file))\n",
    "        image = tf.image.decode_png(image, channels=1)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        image = tf.image.resize(image, [256, 256])  # Resize to 256x256\n",
    "        image = augment_image(image)  # Apply augmentation\n",
    "        image = image.numpy()  # Convert to numpy array\n",
    "        \n",
    "        song_to_clips[song_id].append((image, GENRE_TO_INDEX[genre]))\n",
    "\n",
    "# Convert dictionary to list format\n",
    "song_ids = list(song_to_clips.keys())\n",
    "train_ids, test_ids = train_test_split(song_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, y_train, X_test, y_test = [], [], [], []\n",
    "\n",
    "# Assign clips based on the train-test split\n",
    "for song_id in song_ids:\n",
    "    clips = song_to_clips[song_id]\n",
    "    if song_id in train_ids:\n",
    "        for image, label in clips:\n",
    "            X_train.append(image)\n",
    "            y_train.append(label)\n",
    "    else:\n",
    "        for image, label in clips:\n",
    "            X_test.append(image)\n",
    "            y_test.append(label)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(f\"Train set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)),\n",
    "    Normalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Normalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    Normalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    Normalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(128, activation='relu'), \n",
    "    Dense(len(GENRES), activation='softmax')  # Output size matches number of genres\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Learning rate adjustment\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), batch_size=32, callbacks=[reduce_lr])\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {evaluation[1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Medium (5 random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from sklearn.metrics import confusion\n",
    "import numpy as NP\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnn_preds = np.argmax(model.predict(X_test), axis=1)\n",
    "cnn_cm = confusion_matrix(y_test, cnn_preds)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cnn_cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=GENRES, yticklabels=GENRES)\n",
    "plt.title(\"CNN Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
